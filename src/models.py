import torch
import torch.nn as nn
from omegaconf import DictConfig


def get_model(cfg: DictConfig):
    # Create model based on configuration
    model_kwargs = {k: v for k, v in cfg.model.items() if k != "type"}
    model_kwargs["n_input_channels"] = len(cfg.data.input_vars)
    model_kwargs["n_output_channels"] = len(cfg.data.output_vars)
    
    # Add output spatial dimensions from data config if model needs them
    # These are assumed to be present in cfg.data, e.g., cfg.data.output_height
    # For this competition, these are fixed (48, 72)
    # You might need to add output_height/width to your data config or handle them here
    model_kwargs["output_height"] = cfg.data.get("output_height", 48) # Default to 48 if not in config
    model_kwargs["output_width"] = cfg.data.get("output_width", 72)   # Default to 72 if not in config

    if cfg.model.type == "simple_cnn":
        model = SimpleCNN(**model_kwargs)
    elif cfg.model.type == "cnnlstm":
        model = CNNLSTM(**model_kwargs)
    else:
        raise ValueError(f"Unknown model type: {cfg.model.type}")
    return model


# --- Model Architectures ---


class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=kernel_size // 2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size // 2)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # Skip connection
        self.skip = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.skip = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride), nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        out += self.skip(identity)
        out = self.relu(out)

        return out


class SimpleCNN(nn.Module):
    def __init__(
        self,
        n_input_channels,
        n_output_channels,
        kernel_size=3,
        init_dim=64,
        depth=4,
        dropout_rate=0.2,
        output_height=None,
        output_width=None,
    ):
        super().__init__()

        # Initial convolution to expand channels
        self.initial = nn.Sequential(
            nn.Conv2d(n_input_channels, init_dim, kernel_size=kernel_size, padding=kernel_size // 2),
            nn.BatchNorm2d(init_dim),
            nn.ReLU(inplace=True),
        )

        # Residual blocks with increasing feature dimensions
        self.res_blocks = nn.ModuleList()
        current_dim = init_dim

        for i in range(depth):
            out_dim = current_dim * 2 if i < depth - 1 else current_dim
            self.res_blocks.append(ResidualBlock(current_dim, out_dim))
            if i < depth - 1:  # Don't double the final layer
                current_dim *= 2
        
        self.feature_dim_after_res_blocks = current_dim

        # Conditionally create final layers and dropout
        if n_output_channels > 0:
            self.dropout = nn.Dropout2d(dropout_rate)
            self.final_convs = nn.Sequential(
                nn.Conv2d(self.feature_dim_after_res_blocks, self.feature_dim_after_res_blocks // 2, kernel_size=kernel_size, padding=kernel_size // 2),
                nn.BatchNorm2d(self.feature_dim_after_res_blocks // 2),
                nn.ReLU(inplace=True),
                nn.Conv2d(self.feature_dim_after_res_blocks // 2, n_output_channels, kernel_size=1),
            )
        else:
            # This implies feature extraction mode (n_output_channels <= 0)
            self.dropout = None
            self.final_convs = None

    def extract_features(self, x):
        x = self.initial(x)
        for res_block in self.res_blocks:
            x = res_block(x)
        return x # Shape: (B, self.feature_dim_after_res_blocks, H, W)

    def forward(self, x):
        features = self.extract_features(x)
        
        # Only apply dropout and final_convs if they exist (i.e., not in feature extraction mode)
        if self.final_convs is not None and self.dropout is not None:
            out = self.dropout(features)
            out = self.final_convs(out)
            return out
        else:
            # In feature extraction mode (e.g., when called by CNNLSTM via extract_features)
            # or if SimpleCNN's forward is called directly but it was configured as extractor.
            return features

#GENERATED BY GEMINI 2.5-pro-experimental
class CNNLSTM(nn.Module):
    def __init__(
        self,
        n_input_channels,
        n_output_channels,
        output_height,
        output_width,
        cnn_kernel_size=3,
        cnn_init_dim=64,
        cnn_depth=4,
        cnn_dropout_rate=0.2,
        lstm_hidden_dim=256,
        n_lstm_layers=2,
        lstm_dropout=0.2,
    ):
        super().__init__()
        self.n_output_channels = n_output_channels
        self.output_height = output_height
        self.output_width = output_width

        self.cnn = SimpleCNN(
            n_input_channels=n_input_channels,
            n_output_channels=-1,
            kernel_size=cnn_kernel_size,
            init_dim=cnn_init_dim,
            depth=cnn_depth,
            dropout_rate=cnn_dropout_rate,
        )
        
        cnn_feature_channels = self.cnn.feature_dim_after_res_blocks

        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
        
        self.lstm = nn.LSTM(
            input_size=cnn_feature_channels,
            hidden_size=lstm_hidden_dim,
            num_layers=n_lstm_layers,
            batch_first=True,
            dropout=lstm_dropout if n_lstm_layers > 1 else 0.0
        )
        
        self.fc_decoder = nn.Linear(lstm_hidden_dim, n_output_channels * output_height * output_width)

    def forward(self, x, h_0=None, c_0=None):
        batch_size, seq_len, C_in, H_in, W_in = x.shape
        
        cnn_input = x.reshape(batch_size * seq_len, C_in, H_in, W_in)
        cnn_features = self.cnn.extract_features(cnn_input)
        
        pooled_features = self.adaptive_pool(cnn_features)
        
        lstm_input = pooled_features.reshape(batch_size, seq_len, -1)
        
        if h_0 is not None and c_0 is not None:
            lstm_out, (h_n, c_n) = self.lstm(lstm_input, (h_0, c_0))
        else:
            lstm_out, (h_n, c_n) = self.lstm(lstm_input)
        
        decoder_input = lstm_out.reshape(batch_size * seq_len, -1)
        decoded_output = self.fc_decoder(decoder_input)
        
        output = decoded_output.view(
            batch_size, seq_len, self.n_output_channels, self.output_height, self.output_width
        )
        
        return output